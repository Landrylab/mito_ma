{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio import SeqRecord\n",
    "from Bio import Seq\n",
    "from Bio.SeqUtils import GC\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import gzip\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import Levenshtein as lvs\n",
    "import pickle as pkl\n",
    "sns.set(style='ticks', font='DejaVu Sans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_non_zero_file(fpath):  \n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath) > 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nano_strains = pd.read_csv('/mnt/HDD3/mito_nanopore/script/nano_strains.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_order = nano_strains.loc[nano_strains['cross']=='P'].sort_values(by=['ref_name','strain'])['strain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export library filenames for ncbi\n",
    "filenames_list = []\n",
    "for s in nano_strains.loc[nano_strains['cross']=='P'].index:\n",
    "    paths = nano_strains.loc[s, 'path']\n",
    "    d = re.search('(.+)(/2019\\*)(.+)(\\*\\.fastq.gz)', paths)#.group(1)\n",
    "    if d:\n",
    "        parent_d = d.group(1)\n",
    "        child_d = [i for i in os.listdir(parent_d) if i[:4]=='2019'][0]\n",
    "        d = f'{parent_d}/{child_d}{d.group(3)}'\n",
    "    else:\n",
    "        d = re.search('(.+)(\\*\\.fastq.gz)', paths).group(1)\n",
    "    files = [f for f in os.listdir(d) if f.split('.')[-1]=='gz']\n",
    "    filenames_list.append('\\t'.join([s]+files))\n",
    "#with open('/home/mathieu/mhenault_landrylab/Experiments/MA_2019/ncbi_submissions/filenames_parents.tsv', 'w') as handle:\n",
    "#    handle.write('\\n'.join(filenames_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_color = {'MSH-604':'red',\n",
    "                   'UWOPS-91-202':'red',\n",
    "                   'LL2012_021':'darkred',\n",
    "                   'LL2012_028':'darkred',\n",
    "                   'LL2011_004':'dodgerblue',\n",
    "                   'LL2011_009':'dodgerblue',\n",
    "                   'MSH-587-1':'midnightblue',\n",
    "                   'LL2011_012':'midnightblue',\n",
    "                   'LL2011_001':'midnightblue',\n",
    "                   'YPS644':'limegreen',\n",
    "                   'YPS744':'limegreen',\n",
    "                   'LL2013_040':'dimgrey',\n",
    "                   'LL2013_054':'dimgrey'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MtDNA assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a compound reference genome to bait mitochondrial reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat mt refs and append them to the ref genomes\n",
    "mt_ref = ['/home/mathieu/mhenault_landrylab/Sequences/ref_genomes/CBS432_pacbio/CBS432.mt.genome.fa',\n",
    "          '/home/mathieu/mhenault_landrylab/Sequences/ref_genomes/YPS138_pacbio/YPS138.mt.genome.fa',\n",
    "          '/home/mathieu/mhenault_landrylab/Sequences/ref_genomes/S288C_pacbio/S288c.mt.genome.fa']\n",
    "mt_ref_len = {}\n",
    "MT = []\n",
    "for path in mt_ref:\n",
    "    with open(path, 'r') as fi:\n",
    "        seq = SeqIO.read(fi, 'fasta').seq\n",
    "        MT.append(str(seq))\n",
    "    mt_ref_len[path] = len(seq)\n",
    "        \n",
    "MT = ('N'*100).join(MT)\n",
    "MT = np.apply_along_axis(lambda x: ''.join(x), 1, np.array(list(MT)+list('N'*29)).reshape(-1, 60))\n",
    "MT = '\\n'.join(MT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw reads baited from mapping to PacBio refs\n",
    "RL = {}\n",
    "for s in nano_strains.loc[nano_strains['cross']=='P'].index:\n",
    "    with gzip.open(f'/mnt/HDD3/mito_nanopore/bait/mito_reads_{s}.fastq.gz', 'rt') as fi:\n",
    "        RL[s] = [len(i.seq) for i in SeqIO.parse(fi, 'fastq')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_stats = []\n",
    "for s in RL:\n",
    "    read_stats.append([s, len(RL[s]), np.median(RL[s])])\n",
    "read_stats = pd.DataFrame(read_stats, columns=['strain','n','median'])\n",
    "read_stats.index = read_stats['strain'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize assembly parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = []\n",
    "for (s,k,p,l) in itertools.product(nano_strains.loc[nano_strains['cross']=='P'].index,\n",
    "                                   [23,21,19,17,15,13,11],\n",
    "                                   [8,5,2,1,0],\n",
    "                                   [4096,2048,1024]):\n",
    "    opt.append([f'{s}.{k}.{p}.{l}', s, k, p, l])\n",
    "opt = pd.DataFrame(opt, columns=['dir','strain','k','p','l'])\n",
    "opt['ref_mt'] = nano_strains.loc[opt['strain'], 'ref_mt'].apply(lambda x: x.replace('Users','home')).values\n",
    "opt.index = opt['dir'].values\n",
    "\n",
    "with open('/mnt/HDD3/mito_nanopore/wtdbg2/test/cns.txt') as fi:\n",
    "    cns_list = fi.read().splitlines()\n",
    "opt['cns'] = False\n",
    "for d in opt.index:\n",
    "    if f'{d}.cns.fa' in cns_list:\n",
    "        # test if file is not empty\n",
    "        with open(f'/mnt/HDD3/mito_nanopore/wtdbg2/test/{d}/{d}.cns.fa') as fi:\n",
    "            seq = [i for i in SeqIO.parse(fi, 'fasta')]\n",
    "            if len(seq) != 0:\n",
    "                opt.loc[d, 'cns'] = True\n",
    "\n",
    "#opt.to_csv('/mnt/HDD3/mito_nanopore/mummer/opt_mummer.csv')\n",
    "opt['coords'] = opt['dir'].apply(lambda x: is_non_zero_file(f'/mnt/HDD3/mito_nanopore/mummer/{x}.coords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "OPT = []\n",
    "for i in opt.loc[opt['coords']].index:\n",
    "    \n",
    "    # parse assembly\n",
    "    cns = {}\n",
    "    d = opt.loc[i, 'dir']\n",
    "    with open(f'/mnt/HDD3/mito_nanopore/wtdbg2/test/{d}/{d}.cns.fa') as fi:\n",
    "        for tig in SeqIO.parse(fi, 'fasta'):\n",
    "            cns[tig.id] = tig\n",
    "    sizes = [len(tig.seq) for tig in cns.values()]\n",
    "    assembly_size = sum(sizes)\n",
    "    n_contigs = len(sizes)\n",
    "    largest = max(sizes)\n",
    "    \n",
    "    if is_non_zero_file(f'/mnt/HDD3/mito_nanopore/mummer/{d}.coords'):\n",
    "        \n",
    "        delta = pd.read_csv(f'/mnt/HDD3/mito_nanopore/mummer/{d}.coords', sep='\\t', skiprows=range(4), index_col=None, header=None)\n",
    "        tig_order = delta.groupby(10).apply(lambda x: x[[0,1]].mean(axis=1).mean()).sort_values()\n",
    "        tig_rank = pd.Series(range(tig_order.shape[0]), index=tig_order.index)\n",
    "        tig_len = pd.Series(np.cumsum([0]+[len(cns[tig].seq) for tig in tig_order.index[:-1]]), index=tig_order.index)\n",
    "\n",
    "        ref_len = mt_ref_len[opt.loc[i, 'ref_mt']]\n",
    "        ref_cov = np.zeros(ref_len)\n",
    "        for c1,c2 in delta[[0,1]].values:\n",
    "            ref_cov[c1-1:c2] += 1\n",
    "\n",
    "        OPT.append(list(opt.loc[i].values)+[delta[4].sum(), delta[5].sum(), delta[6].mean(), assembly_size, ref_len, n_contigs, largest, np.where(ref_cov==1, 1, 0).mean(), np.std(ref_cov)])\n",
    "\n",
    "        if plot:\n",
    "            \n",
    "            delta['cns_start'] = delta[2]+tig_len.loc[delta[10]].values\n",
    "            delta['cns_end'] = delta[3]+tig_len.loc[delta[10]].values\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=[7,7])\n",
    "\n",
    "            for i in delta.index:\n",
    "                ax.plot(delta.loc[i, [0,1]], delta.loc[i, ['cns_start','cns_end']], color='k')\n",
    "            for i in tig_len.index:\n",
    "                ax.axhline(tig_len.loc[i], lw=0.5, color='grey')\n",
    "                ax.text(ax.axis()[1]-5e3, tig_len.loc[i]+1e3, s=i, ha='right')\n",
    "            ax.set_title(d)\n",
    "            ax.set_xlabel('YPS138')\n",
    "            ax.set_ylabel(f'{d} cns')\n",
    "            ax.margins(0)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            #plt.savefig(f'/mnt/HDD3/mito_nanopore/mummer/fig/{d}_cns.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "OPT = pd.DataFrame(OPT, columns=['dir','strain','k','p','l','ref_mt','cns','coords','Rcov','Qcov','ident','Qlen', 'Rlen','n_contigs','largest','Rcov_1','Rcov_std']).astype({'k':int,'p':int,'l':int})\n",
    "OPT['QCov'] = OPT['Qcov']/OPT['Qlen']\n",
    "OPT['RCov'] = OPT['Rcov']/OPT['Rlen']\n",
    "OPT['QRmean'] = OPT[['QCov','RCov']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute score that includes deviation from expected coverage and contiguity\n",
    "OPT['contiguity'] = 1/OPT['largest']\n",
    "OPT['dev'] = OPT[['QCov','Rcov_1']].apply(lambda x: np.sum(np.abs(x-1)), axis=1)\n",
    "score_comp = OPT[['dev','contiguity']]\n",
    "OPT['score'] = ((score_comp-score_comp.mean())/score_comp.std()).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add read stats\n",
    "OPT['n'] = read_stats.loc[OPT['strain'], 'n'].values\n",
    "OPT['median'] = read_stats.loc[OPT['strain'], 'median'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory variables\n",
    "OPT['dummy_k.p'] = OPT.apply(lambda x: f'{x[\"strain\"]}.{x[\"k\"]}.{x[\"p\"]}', axis=1)\n",
    "OPT['dummy_k.l'] = OPT.apply(lambda x: f'{x[\"strain\"]}.{x[\"k\"]}.{x[\"l\"]}', axis=1)\n",
    "OPT['dummy_l.p'] = OPT.apply(lambda x: f'{x[\"strain\"]}.{x[\"l\"]}.{x[\"p\"]}', axis=1)\n",
    "for s, df in OPT.sort_values(by='dev', ascending=False).groupby('strain'):\n",
    "    OPT.loc[df.index, 'rank_dev'] = np.linspace(0,1,df.shape[0])\n",
    "\n",
    "interactions = []\n",
    "for interaction_size in [1,2,3]:\n",
    "    for i in itertools.combinations(['k','p','l'], interaction_size):\n",
    "        terms = ['median']+list(i)\n",
    "        name = '*'.join(terms)\n",
    "        d = OPT[terms]\n",
    "        interactions.append(name)\n",
    "        OPT[name] = ((d-d.mean())/d.std()).apply(lambda x: np.prod(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10 = OPT.sort_values(by='dev').groupby('strain').apply(lambda x: x.iloc[:10])\n",
    "\n",
    "for f in ['k','p','l']:\n",
    "    \n",
    "    for q, ls in zip([0.05, 0.5], [':','-']):\n",
    "    \n",
    "\n",
    "        df = OPT.groupby(['strain','n',f])['score'].apply(lambda x: np.quantile(x, q)).reset_index()\n",
    "        sns.lineplot(x=f, y='score', hue='n', palette='viridis', ls=ls, lw=0.5, legend=False, data=df)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = OPT.sort_values(by='score', ascending=True).groupby('strain').apply(lambda x: x.iloc[0])['dir']\n",
    "#with open('/Volumes/Seagate/mito_nanopore/wtdbg2/best_assemblies.txt', 'w') as fo:\n",
    "#    fo.write('\\n'.join(best.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circularize assembies at the start of ATP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_atp6 = pd.read_csv('/Volumes/Seagate/mito_nanopore/circularization/breakpoint_atp6.csv', header=None, index_col=0)\n",
    "\n",
    "CIRC = {}\n",
    "CIRC_dup = {}\n",
    "for d in best:\n",
    "    # parse uncircularized contig\n",
    "    to_circ = {}\n",
    "    with open(f'/Volumes/Seagate/mito_nanopore/wtdbg2/test/{d}/{d}.cns.fa') as fi:\n",
    "        for tig in SeqIO.parse(fi, 'fasta'):\n",
    "            to_circ[tig.id] = tig\n",
    "    # parse breakpoint at atp6\n",
    "    s = d.split('.')[0]\n",
    "    pos, strand = breakpoint_atp6.loc[s, [2,3]]\n",
    "    # select \n",
    "    seq = to_circ['ctg1'].seq\n",
    "    # circularize\n",
    "    if strand == '+':\n",
    "        pos -= 1\n",
    "    print(s, len(seq[pos:]), len(seq[:pos]))\n",
    "    Seq = seq[pos:] + seq[:pos]\n",
    "    #reverse complement if needed\n",
    "    if strand == '-':\n",
    "        Seq = Seq.reverse_complement()\n",
    "    # store\n",
    "    sr = SeqRecord.SeqRecord(seq=Seq, id=f'mt.{s}', description='')\n",
    "    \n",
    "    CIRC[s] = sr\n",
    "\n",
    "#for s in CIRC:\n",
    "#    with open(f'/Volumes/Seagate/mito_nanopore/circularization/{s}.circ.fasta', 'w') as fo:\n",
    "#        SeqIO.write(CIRC[s], fo, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute levenshtein distance between windiws close to the breakpoint\n",
    "bw = 20\n",
    "step = 7\n",
    "wdw = 500\n",
    "\n",
    "for s in CIRC:\n",
    "\n",
    "    seq = CIRC[s].seq\n",
    "    # 2.5 kb on each side of the breakpoint\n",
    "    pos, strand = breakpoint_atp6.loc[s, [2,3]]\n",
    "    if strand == '+':\n",
    "        # convert position of the breakpoint\n",
    "        pos = len(CIRC[s].seq)-pos\n",
    "    start, end = pos-wdw, pos+wdw\n",
    "\n",
    "    distance = []\n",
    "    bin_seq = {i+0.5*bw:str(seq[i:i+bw]) for i in np.arange(start, end-bw, step)}\n",
    "    for (i1,b1), (i2,b2) in itertools.combinations(bin_seq.items(), 2):\n",
    "        #similarity = (b1 == b2).mean()\n",
    "        d = lvs.distance(b1, b2)\n",
    "        distance.append([i1, i2, d])\n",
    "\n",
    "    dat = pd.pivot_table(pd.DataFrame(distance), index=0, columns=1, values=2)\n",
    "    fig, ax = plt.subplots(figsize=[10,10])\n",
    "    sns.heatmap(dat, cmap='viridis', ax=ax)\n",
    "    ax.set_title(f'{s} {pos}')\n",
    "\n",
    "    ax.axvline(70, color='red', lw=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'/Volumes/Seagate/mito_nanopore/circularization/distance/levenshtein.{bw}.{step}.{wdw}.{s}.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tandem duplications at the artificial breakpoint site\n",
    "remove_dup = pd.read_csv('/Volumes/Seagate/mito_nanopore/circularization/remove_dup.csv', header=None, index_col=0)\n",
    "\n",
    "CIRC_RD = {}\n",
    "for s, sr in CIRC.items():\n",
    "    start, end = remove_dup.loc[s]\n",
    "    seq1 = sr.seq[:start-1]\n",
    "    seq2 = sr.seq[end:]\n",
    "    \n",
    "    nsr = SeqRecord.SeqRecord(seq=seq1+seq2, id='mt', description='')\n",
    "    CIRC_RD[s] = nsr\n",
    "    \n",
    "    # export mt genomes alone\n",
    "    #with open(f'/Volumes/Seagate/mito_nanopore/circularization/{s}.circ.rd.fasta', 'w') as fo:\n",
    "    #    SeqIO.write(CIRC_RD[s], fo, 'fasta') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of coverage of baited reads on refs\n",
    "DEPTH_BAIT = {}\n",
    "for s in nano_strains.loc[nano_strains['cross']=='P'].index:\n",
    "    depth = pd.read_csv(f'/Volumes/Seagate/mito_nanopore/minimap2/{s}.bait.concat_mt.sorted.depth', sep='\\t', header=None)\n",
    "    for ref, df in depth.groupby(0):\n",
    "        depth.loc[df.index, 'bin'] = pd.cut(df[1], np.arange(0, df[1].max(), 1000))\n",
    "    depth = depth.groupby([0,'bin'])[2].mean().reset_index()\n",
    "    depth['pos'] = depth['bin'].apply(lambda x: np.mean([x.left,x.right]))\n",
    "    DEPTH_BAIT[s] = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, df in DEPTH_BAIT.items():\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for ref, df1 in df.groupby(0):\n",
    "        ax.plot(df1['pos'], df1[2])\n",
    "    ax.set_title(s)\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polished assemblies\n",
    "CORR = {}\n",
    "\n",
    "for s in strain_order:\n",
    "    with open(f'/mnt/HDD3/mito_nanopore/polishing/{s}/{s}.nanopolish.pilon.fasta') as handle:\n",
    "        CORR[s] = SeqIO.read(handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mfannot gff files\n",
    "GFF = []\n",
    "\n",
    "for s in nano_strains.loc[nano_strains['cross']=='P', 'strain']:\n",
    "    \n",
    "    gff = pd.read_csv(f'/mnt/HDD3/mito_nanopore/mfannot/{s}.mfannot.gff', sep='\\t', skiprows=1, header=None)\n",
    "    fields = gff[8].apply(lambda x: pd.Series(dict([i.split('=') for i in x.split(';')])))\n",
    "    fields['strain'] = s\n",
    "    \n",
    "    GFF.append(pd.concat([gff, fields], axis=1))\n",
    "\n",
    "GFF = pd.concat(GFF).reset_index(drop=True)\n",
    "\n",
    "GFF['strain_order'] = pd.Series(range(13), index=strain_order).loc[GFF['strain']].values\n",
    "\n",
    "GFF['annot_color'] = 'k'\n",
    "GFF['annot_type'] = 'k'\n",
    "GFF['annot_width'] = 1\n",
    "GFF['annot_plot_order'] = 0\n",
    "\n",
    "for f, df in GFF.groupby('gene'):\n",
    "    if 'trn' in f:\n",
    "        GFF.loc[df.index, 'annot_color'] = 'limegreen'\n",
    "        GFF.loc[df.index, 'annot_type'] = 'tRNA'\n",
    "        GFF.loc[df.index, 'annot_width'] = 1\n",
    "        GFF.loc[df.index, 'annot_plot_order'] = 1\n",
    "    if '-E' in f:\n",
    "        GFF.loc[df.index, 'annot_color'] = 'blue'\n",
    "        GFF.loc[df.index, 'annot_type'] = 'exon'\n",
    "        GFF.loc[df.index, 'annot_width'] = 0.5\n",
    "        GFF.loc[df.index, 'annot_plot_order'] = 3\n",
    "    if '-I' in f:\n",
    "        GFF.loc[df.index, 'annot_color'] = 'white'\n",
    "        GFF.loc[df.index, 'annot_type'] = 'intron'\n",
    "        GFF.loc[df.index, 'annot_width'] = 0.5\n",
    "        GFF.loc[df.index, 'annot_plot_order'] = 4\n",
    "    if 'orf' in f:\n",
    "        GFF.loc[df.index, 'annot_color'] = 'red'\n",
    "        GFF.loc[df.index, 'annot_type'] = 'orf'\n",
    "        GFF.loc[df.index, 'annot_width'] = 0.3\n",
    "        GFF.loc[df.index, 'annot_plot_order'] = 5\n",
    "    if f in ['atp6', 'cob', 'atp9', 'rps3', 'cox3', 'cox2', 'rnpB', 'cox1', 'atp8']:\n",
    "        GFF.loc[df.index, 'annot_color'] = 'dodgerblue'\n",
    "        GFF.loc[df.index, 'annot_type'] = 'gene'\n",
    "        GFF.loc[df.index, 'annot_width'] = 1\n",
    "        GFF.loc[df.index, 'annot_plot_order'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-import final gff\n",
    "GFF = pd.read_csv('/mnt/HDD3/mito_nanopore/mfannot/gff_edit.csv', sep='\\t')\n",
    "GFF.columns = list(range(9)) + list(GFF.columns[9:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curation of MFannot annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export features by blocks; define anchors as well preserved genes\n",
    "anchors = ['atp6','cob','atp9','rps3','cox2','cox3','rnpB','rns','cox1','atp8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the atp6 initial positions\n",
    "GFF.loc[GFF['gene']=='atp6', 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export GFF for manual editing\n",
    "#GFF.sort_values(by=['annot_type','strain',3,4]).to_csv('/mnt/HDD3/mito_nanopore/mfannot/gff.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import edited GFF\n",
    "GFF = pd.read_csv('/mnt/HDD3/mito_nanopore/mfannot/gff_edit.csv', sep='\\t')\n",
    "GFF.columns = list(range(9)) + list(GFF.columns)[9:]\n",
    "GFF = GFF.astype({3:int,4:int,'strain_order':int,'annot_width':float,'annot_plot_order':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export sequences of main genes\n",
    "for s, df in GFF.loc[GFF['gene'].isin(anchors)].sort_values(by=3).groupby('strain'):\n",
    "    \n",
    "    # for each anchor, take the sequence of the anchor itself and the following block\n",
    "    for i in range(df.shape[0]):\n",
    "        a = df.iloc[i, 12]\n",
    "        ca1, ca2 = df.iloc[i, 3], df.iloc[i, 4]\n",
    "        if i == df.shape[0]-1:\n",
    "            ci2 = len(CORR[s].seq)+1\n",
    "        else:\n",
    "            ci2 = df.iloc[i+1, 3]\n",
    "        # add anchor\n",
    "        \n",
    "        anchor_id = f'{a}.anchor.{s}.{ca1-1}.{ca2}'\n",
    "        inter_id = f'{a}.inter.{s}.{ca2-1}.{ci2}'\n",
    "        \n",
    "        #with open(f'/mnt/HDD3/mito_nanopore/muscle/fasta/{anchor_id}.fasta', 'w') as handle:\n",
    "        #    SeqIO.write(SeqRecord.SeqRecord(CORR[s].seq[ca1-1:ca2], id=anchor_id, description=''), handle, 'fasta')\n",
    "        #with open(f'/mnt/HDD3/mito_nanopore/muscle/fasta/{inter_id}.fasta', 'w') as handle:\n",
    "        #    SeqIO.write(SeqRecord.SeqRecord(CORR[s].seq[ca2:ci2-1], id=inter_id, description=''), handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output list of sequence blocks\n",
    "#with open('/mnt/HDD3/mito_nanopore/muscle/list_blocks.txt', 'w') as handle:\n",
    "#    handle.write('\\n'.join([f'{i}.anchor\\n{i}.inter' for i in anchors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cob and cox1, extract spliced cds\n",
    "for a in ['cob', 'cox1']:\n",
    "    for s, df in GFF.loc[(GFF['annot_type']=='exon') & (GFF['gene'].apply(lambda x: a in x))].sort_values(by=3).groupby('strain'):\n",
    "        seq = []\n",
    "        for i in df.index:\n",
    "            start, end = df.loc[i, [3,4]]\n",
    "            seq.append(str(CORR[s].seq[start-1:end]))\n",
    "        seq = Seq.Seq(''.join(seq))\n",
    "        name = f'{a}.spliced.{s}.{start}.{end}'\n",
    "        with open(f'/mnt/HDD3/mito_nanopore/muscle/fasta/{name}.fasta', 'w') as handle:\n",
    "            SeqIO.write(SeqRecord.SeqRecord(seq=seq, id=name, description=''), handle, 'fasta')\n",
    "#with open('/mnt/HDD3/mito_nanopore/muscle/list_spliced.txt', 'w') as handle:\n",
    "#    handle.write('\\n'.join([f'{i}.spliced' for i in ['cob','cox1']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sequences from ref assemblies\n",
    "REF_ASSEMBLIES = {}\n",
    "for s in ['S288C','CBS432','CBS7400']:\n",
    "    with open(f'/home/mathieu/mhenault_landrylab/Sequences/ref_genomes/mt_introns/{s}.mt.fasta') as handle:\n",
    "        REF_ASSEMBLIES[s] = SeqIO.read(handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gff annotations of reference mtDNAs\n",
    "REF_GFF = []\n",
    "\n",
    "for s in REF_ASSEMBLIES:\n",
    "    \n",
    "    gff = pd.read_csv(f'/home/mathieu/mhenault_landrylab/Sequences/ref_genomes/mt_introns/{s}.mt.gff3', sep='\\t', skiprows=2, header=None)\n",
    "    fields = gff[8].apply(lambda x: pd.Series(dict([i.split('=') for i in x.split(';')])))\n",
    "    fields['strain'] = s\n",
    "    \n",
    "    REF_GFF.append(pd.concat([gff, fields], axis=1))\n",
    "\n",
    "REF_GFF = pd.concat(REF_GFF).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output ref intron sequences\n",
    "ref_introns = []\n",
    "for i in REF_GFF.loc[REF_GFF[2]=='intron'].index:\n",
    "    s, start, end, name = REF_GFF.loc[i, ['strain',3,4,'Note']]\n",
    "    ref_introns.append(SeqRecord.SeqRecord(seq=REF_ASSEMBLIES[s].seq[start-1:end], id=name.replace(' ', '.'), description=''))\n",
    "#with open('/mnt/HDD3/mito_nanopore/introns/ref_introns.fasta', 'w') as handle:\n",
    "#    SeqIO.write(ref_introns, handle, 'fasta')\n",
    "    \n",
    "# output query intron sequences\n",
    "query_introns = []\n",
    "for i in GFF.loc[GFF['annot_type']=='intron'].index:\n",
    "    s, start, end, name = GFF.loc[i, ['strain',3,4,'gene']]\n",
    "    query_introns.append(SeqRecord.SeqRecord(seq=CORR[s].seq[start-1:end], id=f'{name}.{s}', description=''))\n",
    "#with open('/mnt/HDD3/mito_nanopore/introns/query_introns.fasta', 'w') as handle:\n",
    "#    SeqIO.write(query_introns, handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import intron blastn results\n",
    "blastn_introns = pd.read_csv('/mnt/HDD3/mito_nanopore/introns/introns_blastn.tab', sep='\\t', header=None)\n",
    "\n",
    "bi = blastn_introns.sort_values(by=10).groupby(0).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "bi = pd.concat([bi, bi[0].apply(lambda x: pd.Series(x.split('.'), index=['intron','strain']))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the sequences of curated intron annotations for MSA\n",
    "# goal is to check intron boundaries to see if they agree well, and verify the extent of variation between strains \n",
    "introns = {}\n",
    "for i, df in GFF.loc[GFF['annot_type']=='intron'].sort_values(by='strain_order').groupby('Name'):\n",
    "    introns[i] = []\n",
    "    for j in df.index:\n",
    "        start, end, s = df.loc[j, [3,4,'strain']]\n",
    "        introns[i].append(SeqRecord.SeqRecord(seq=CORR[s].seq[start-1:end], id=f'{i}.{s}', description=''))\n",
    "#for i in introns:\n",
    "#    with open(f'/mnt/HDD3/mito_nanopore/muscle/fasta/{i}.fasta', 'w') as handle:\n",
    "#        SeqIO.write(introns[i], handle, 'fasta')\n",
    "# output list of introns\n",
    "#with open('/mnt/HDD3/mito_nanopore/muscle/list_introns.txt', 'w') as handle:\n",
    "#    handle.write('\\n'.join([i for i in introns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export orf sequences for alignment\n",
    "orfs = {}\n",
    "for o, df in GFF.loc[GFF['annot_type']=='orf'].sort_values(by='strain_order').groupby('Name'):\n",
    "    if 'ai' not in o and 'bi' not in o:\n",
    "        orfs[o] = []\n",
    "        for s, df1 in df.groupby('strain'):\n",
    "            start = df1[3].min()\n",
    "            end = df1[4].max()\n",
    "            orfs[o].append(SeqRecord.SeqRecord(seq=CORR[s].seq[start-1:end], id=f'{o}.{s}', description=''))\n",
    "#for o in orfs:\n",
    "#    with open(f'/mnt/HDD3/mito_nanopore/muscle/fasta/{o}.fasta', 'w') as handle:\n",
    "#        SeqIO.write(orfs[o], handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all features for search against assemblies\n",
    "ref_feats = []\n",
    "for (s, start, end), df in REF_GFF.loc[REF_GFF['gbkey']!='Src'].sort_values(by='gbkey').groupby(['strain',3,4]):\n",
    "\n",
    "    name = f'{s}.' + '_'.join(np.unique(df.dropna(axis=1).iloc[:, 9:].values)).replace(' ', '.') + f'.idx{df.index[0]}'\n",
    "    \n",
    "    ref_feats.append(SeqRecord.SeqRecord(seq=REF_ASSEMBLIES[s].seq[start-1:end], id=name, description=''))\n",
    "    \n",
    "#with open('/mnt/HDD3/mito_nanopore/features/ref_features.fasta', 'w') as handle:\n",
    "#    SeqIO.write(ref_feats, handle, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of artificial reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the mtDNA with largest feature set as template (LL2012_028)\n",
    "artificial_genome = copy.copy(CORR['LL2012_028'])\n",
    "artificial_genome.description = ''\n",
    "\n",
    "# coordinates of introns to complement in LL2012_028\n",
    "ai3gamma = 56, 69566\n",
    "bi5 = 755, 11224\n",
    "bi4 = 752, 11174\n",
    "bi3 = 12, 10924\n",
    "intron_length = []\n",
    "\n",
    "for i, intron in enumerate([ai3gamma, bi5, bi4, bi3]):\n",
    "    s, c1, c2 = GFF.loc[intron[0], ['strain',3,4]]\n",
    "    intron_length.append(c2-c1+1)\n",
    "    pos = intron[1]\n",
    "    print(artificial_genome.seq[pos-20:pos])\n",
    "    artificial_genome.seq = artificial_genome.seq[:pos] + CORR[s].seq[c1-1:c2] + artificial_genome.seq[pos:]\n",
    "    artificial_genome.id = 'mt_art'\n",
    "    \n",
    "# export artificial reference genome\n",
    "#with open('/mnt/HDD3/mito_nanopore/artificial_genome/artificial_genome.fasta', 'w') as handle:\n",
    "#    SeqIO.write(artificial_genome, handle, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment of final mtDNA assemblies to S288c reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mummer coords files\n",
    "COORDS_S288c= {}\n",
    "for s in nano_strains.loc[nano_strains['cross']=='P', 'strain']:\n",
    "    coords = pd.read_csv(f'/mnt/HDD3/mito_nanopore/mummer_S288c/{s}.coords', sep='\\t', skiprows=4, header=None)\n",
    "    COORDS_S288c[s] = coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[8,8])\n",
    "gs = plt.GridSpec(ncols=4, nrows=4)\n",
    "\n",
    "parents_ax = dict(zip(parents_color, itertools.product(range(4), range(4))))\n",
    "\n",
    "for s, coords in COORDS_S288c.items():\n",
    "    \n",
    "    ax = fig.add_subplot(gs[parents_ax[s]])\n",
    "    \n",
    "    for i in coords.index:\n",
    "        strand, ident = coords.loc[i, [8,6]]\n",
    "        c = parents_color[s]\n",
    "\n",
    "        ax.plot(coords.loc[i, [0,1]], coords.loc[i, [2,3]], c=c, lw=3, label=s)\n",
    "        \n",
    "    ax.set_xlim([-2e3, 85e3])\n",
    "    ax.set_xticks(np.arange(0,85e3,2e4))\n",
    "    ax.set_xticklabels(np.arange(0,85,20), size=9)\n",
    "    ax.set_xlabel('S288c')\n",
    "    ax.set_ylim([-2e3, 85e3])\n",
    "    ax.set_yticks(np.arange(0,85e3,2e4))\n",
    "    ax.set_yticklabels(np.arange(0,85,20), size=9)\n",
    "    ax.set_ylabel(f'{s}')\n",
    "    \n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/mathieu/mhenault_landrylab/Publications/mito_ma/resubmission2_GRes/fig/assemblies.mt_S288c.svg', dpi=300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
